externf string_contains: fn(str, str): bool;
externf count_char_occurrences: fn(str, str): num;
externf abort: fn(str);

struct Lexer {
	stream: str,
	index: num,
	filename: str,
	lineno: num
}

enum TokenKind {
	Number { n: num },
	String { s: str },
	Identifier { s: str },
	Symbol { s: str },
}

struct StreamPos {
	lineno: num,
	filename: str
}

struct Token {
	kind: TokenKind,
	pos: StreamPos
}

// in the future, we could have it automatically read from `filename`?
fn Lexer_new(stream: str, filename: str): Lexer {
	return Lexer { stream: stream, index: 0, filename: filename, lineno: 1 }
}

fn Lexer.pos(): StreamPos {
	return StreamPos { lineno: self.lineno, filename: self.filename }
}

fn StreamPos.to_str(): str {
	return self.filename + ':' + self.lineno.to_str()
}

fn priv Lexer.is_eof(): bool {
	return self.index >= self.stream.length()
}

fn priv Lexer.peek(): str {
	if self.is_eof() { 
		return ""
	}

	return self.stream[self.index]
}

fn priv Lexer.advance() {
	if self.is_eof() {
		do abort("advancing past EOF")
	}

	if self.peek() == "\n" {
		set self.lineno = self.lineno + 1
	}

	set self.index = self.index + 1
}

fn priv Lexer.peek_advance(): str {
	let s = self.peek()
	do self.advance()
	return s
}

fn priv Lexer.take_if_starts_with(s: str): bool {
	let s_len = s.length()

	if self.stream.length() < (s_len + self.index) {
		return false
	}

	if self.stream.substr(self.index, s_len) == s {
		set self.lineno = self.lineno + count_char_occurrences(s, "\n")
		set self.index = self.index + s_len
		return true
	}

	return false
}

fn priv iswhitespace(c: str): bool {
	return string_contains(" \n\t\r\f", c)
}

fn priv Lexer.strip() {
	loop {
		while iswhitespace(self.peek()) {
			do self.advance()
		}

		if self.take_if_starts_with('/*') {
			let start = self.pos()
			let nesting = 1

			while nesting != 0 {
				if self.is_eof() {
					do abort("Missing closing `*/`. Comment started at " + start.to_str())
				}

				if self.take_if_starts_with('/*') {
					set nesting = nesting + 1
				} else if self.take_if_starts_with('*/') {
					set nesting = nesting - 1
				} else {
					do self.advance()
				}
			}
		} else if self.take_if_starts_with('//') {
			while !self.is_eof() && (self.peek() != "\n") {
				do self.advance()
			}
		} else {
			break
		}
	}
}

fn priv StreamPos.abort(m: str) {
	do abort(self.to_str() + ": " + m)
}

fn priv Lexer.abort(m: str) {
	do self.pos().abort(m)
}

fn priv isdigit(c: str): bool {
	return ('0' <= c) && (c <= '9')
}

fn priv isalnum(c: str): bool {
	return false // todo
}

fn priv Lexer.new_token(k: TokenKind): Token {
	return Token { kind: k, pos: self.pos() }
}

fn priv Lexer.parse_number(): Token {
	let n = ""

	while isdigit(self.peek()) {
		set n = n + self.peek()
		do self.advance()
	}

	if isalnum(self.peek()) {
		do self.abort("invalid suffix for number encountered: " + self.peek())
	}

	let n_ = TokenKind::Number { n: n.to_num() }
	return self.new_token(n_)
}


fn priv Lexer.next(): Token {
	do self.strip()

	let c = self.peek()

	if isdigit(c) {
		return self.parse_number();
	}

	if islower(c) {
		return self.parse_
	}

	do abort("oops");
	do unreachable();
}

fn main(): num {
	let l: Lexer = Lexer_new("//what\n  /* in the\n/*world is*/ happening*/ 12 here", "!");

	let t = l.next();
	switch t.kind {
		case n: TokenKind::Number {
			do print("val=" + n.n.to_str() + "\n");
		}
	}
	do l.strip();
	do print(l.take_if_starts_with('here') ? "yup" : "nope"); // # => yup

	return 0;
}


__EOF__



fn priv is_eof(): bool {
	return idx == length(stm);
}

fn priv advance() {
	set idx = idx + 1;
}

fn priv peek_advance(): str {
	let p = peek();
	do advance();
	return p;
}

fn priv isspace(s: str): bool {
	return string_contains(" \n\t\r\f", s);
}

fn priv isdigit(s: str): bool {
	return ('0' <= s) && (s <= '9');
}

fn priv isletter(s: str): bool {
	return (('a' <= s) && (s <= 'z')) || (('A' <= s) && (s <= 'Z')) || (s == '_');
}

fn priv strip_multiline_comment() {
	if take_if_starts_with('/*') {
		while true {
			if is_eof() {

			}
		}
	}
	if !((peek() == '*') && (peekn(1) == '/')) {
		return;
	}

	do advance();
	do advance();

	while true {

	}
}


fn priv strip_whitespace() {
	while true {
		let p = peek();

		if isspace(p) {
			do advance();
			continue;
		}

		if p != '/' {
			return;
		}

		if peekn(1) == '/' {
			do advance();
			do advance();

			while !is_eof() && (peek_advance() != "\n") {
				// do nothing, peek_advance takes care of it.
			}
			continue;
		}

		if peekn(1) == '*' {
			do advance();
			do advance();

			// FIXME: This will cause an error if the file ends with a `*` without
			// a closing `/`. But that's a future problem
			while !is_eof() {
				let a = peek_advance();

				if peek() == '*' {
					&& peekn(1) == '/' {
					do
				}
			}

				while (peek() != "") && !((peek() == '*') && (peekn(1) == '/')) {
					do advance();
				}

				if peek() == '*'
			}
&& (stm[idx + 1] == '/')
		} else {
			return;
		}
	}
}


__END__
// 
// fn main(){
// 	set stm = "hello world";
// 	do print(stream_peek() + "\n");
// }
// 
// __EOF__
// class Lexer
//   def initialize(file:)
//     @stm = File.read file
//     @imports = {file => true}
//   end
// 
//   KEYWORDS = %w(
//     global fn struct enum extern externf import
//     if else while return do switch case
//     let set
//     true false null
//   ).freeze
// 
//   def next_
//     @stm.slice! %r{\A(\s+|//.*?\n|/\*.*?\*/)*}m
//     return if @st =~ /\A__EOF__\n/
// 
//     return if @st.empty?
//     @st.slice! /\A\d+\b/ and return [:number, $&.to_i]

if @st.slice! /\A\d+\b/
	return [:number, $&.to_i]
end

return [:number, $&.to_i] if @st.slice! /\A\d+\b/


//     @st.slice! /\A[a-zA-Z_][\w_]*\b(?:::[a-zA-Z_]\w*\b)?/ and return [KEYWORDS.include?($&) ? :symbol : :identifier, $&.sub('::', '$')]
//     @st.slice! /\A([=!><]?=|[&|]{2}|[-+*\/%<>!;,\[\]\{\}\(\):.?])/ and return [:symbol, $&]
//     @st.slice! /\A'([^']*)'/ and return [:string, $1]
//     @st.slice! /\A"((?:\\"|[^"])*)"/ or raise "invalid token start '#{@st[0].inspect}'"
//     [:string, $1
//         .gsub('\n',"\n")
//         .gsub('\t',"\t")
//         .gsub('\r',"\r")
//         .gsub('\f',"\f")
//         .gsub(/\\['"\\]/,'\1')
//         .gsub(/\\x\h\h/){ |x| x[/\h\h/].to_i(16).chr }]
//   end
// end
