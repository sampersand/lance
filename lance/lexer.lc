//import "lexer.lch"
//import "utils.lch"

// in the future, we could have it automatically read from `filename`?
fn priv Lexer_new(stream: str, filename: str): Lexer {
	return Lexer { stream, index: 0, filename, lineno: 1 }
}

fn Lexer.pos(): StreamPos {
	return StreamPos { lineno: self.lineno, filename: self.filename }
}

fn StreamPos.to_str(): str {
	return self.filename + ':' + self.lineno.to_str()
}

fn priv Lexer.is_eof(): bool {
	return self.stream.length() <= self.index
}

fn priv Lexer.peek(): str {
	return self.is_eof() ? "" : self.stream[self.index]
}

fn priv Lexer.advance() {
	if self.is_eof() {
		do abort("advanced past EOF")
	}

	if self.peek() == "\n" {
		set self.lineno = self.lineno + 1
	}

	set self.index = self.index + 1
}

fn priv Lexer.peek_advance(): str {
	let s = self.peek()
	do self.advance()
	return s
}

fn priv Lexer.take_while(cond: fn(str): bool): str {
	let s = ""

	while (cond)(self.peek()) && !self.is_eof() {
		set s = s + self.peek()
		do self.advance()
	}

	return s
}

fn priv Lexer.take_if_starts_with(s: str): bool {
	let s_len = s.length()

	if self.stream.length() < (s_len + self.index) {
		return false
	}

	if self.stream.substr(self.index, s_len) == s {
		set self.lineno = self.lineno + count_char_occurrences(s, "\n")
		set self.index = self.index + s_len
		return true
	}

	return false
}

fn StreamPos.abort(m: str): never {
	do abort(self.to_str() + ": " + m)
}

fn priv Lexer.abort(m: str): never {
	do self.pos().abort(m)
}

fn priv isspace(s: str): bool {
	return string_contains(" \n\t\r\f", s)
}

fn priv isdigit(s: str): bool {
	return ('0' <= s) && (s <= '9')
}

fn priv isletter(c: str): bool {
	return (('a' <= c) && (c <= 'z')) || (('A' <= c) && (c <= 'Z')) || (c == '_')
}

fn priv isalnum(c: str): bool {
	return isdigit(c) || isletter(c)
}

fn priv _is_not_eof(s: str): bool {
	return s != "\n"
}

fn priv Lexer.strip_whitespace(): bool {
	return self.take_while(isspace) != ""
}

fn priv Lexer.strip_single_line_comment(): bool {
	if !self.take_if_starts_with('//') {
		return false
	}

	do self.take_while(_is_not_eof)
	return true
}

fn priv Lexer.strip_multiline_comment(): bool {
	if !self.take_if_starts_with('/*') {
		return false
	}

	let start = self.pos()
	let nesting = 1
	while nesting != 0 {
		if self.is_eof() {
			do start.abort("Missing closing `*/`")
		}

		if self.take_if_starts_with('/*') {
			set nesting = nesting + 1
		} else if self.take_if_starts_with('*/') {
			set nesting = nesting - 1
		} else {
			do self.advance()
		}
	}

	return true
}

fn priv Lexer.strip() {
	while self.strip_whitespace()
		|| self.strip_single_line_comment()
		|| self.strip_multiline_comment() 
	{
		/* do nothing, as the strips should do it for us */
	}
}

fn priv Lexer.parse_number(): TokenKind {
	let n = ""

	loop {
		let c = self.peek()

		if isdigit(c) {
			set n = n + c
		} else if c == '_' {
			// do nothing
		} else if isletter(c) {
			do self.abort("bad number suffix " + inspect_str(c))
		} else {
			break
		}

		do self.advance()
	}

	do assert(n != "", "parse number parsed nothing")

	return TokenKind::Number { _: n.to_num() }
}

fn priv iskeyword(s: str): bool {
	let kws = [
		"global", "fn", "priv", "struct", "enum", "extern", "externf", "import",
		"if", "else", "while", "loop", "return", "do", "switch", "case", "break",
		"continue", "let", "set", "true", "false", "null", "unreachable"
	]

	let i = 0
	let len = kws.length()

	while i < len {
		if kws[i] == s {
			return true
		}

		set i = i + 1
	}

	return false
}

fn priv Lexer.parse_identifier(): TokenKind {
	let i = self.take_while(isalnum)
	do assert(i != "", "parsing an identifier returned nothing")

	return iskeyword(i) ? TokenKind::Symbol { _: i } : TokenKind::Identifier { _: i }
}

fn priv tohex(s: str, start: StreamPos): num {
	if isdigit(s) {
		return s.to_num()
	}

	if ('a' <= s) && (s <= 'f') {
		return s.to_ascii() - 97 // 97 is `a` in ascii
	}

	if ('A' <= s) && (s <= 'F') {
		return s.to_ascii() - 64 // 64 is `A` in ascii
	}

	do start.abort("unknown hex character " + inspect_str(s))
}

fn priv Lexer.parse_string(): TokenKind {
	let start = self.pos()
	let quote = self.peek_advance()
	do assert((quote == '"') || (quote == "'"), "invalid starting char for string " + inspect_str(quote))

	let s = ""

	loop {
		if self.is_eof() { do start.abort("Unterminated string encountered") }

		let c = self.peek_advance()
		if c == quote {
			break
		}

		if c != "\\" {
			set s = s + c
			continue
		}

		if self.is_eof() { do start.abort("Unterminated string encountered") }
		set c = self.peek_advance()

		if quote == "'" {
			set s = s + (((c == "\\") || (c == "'")) ? "" : "\\") + c
			continue
		}

		do assert(quote == '"', "quote is not single or double?")

		if string_contains("\"\'\\", c) { set s = s + c; }
		else if c == 'n' { set s = s + "\n"; }
		else if c == 't' { set s = s + "\t"; }
		else if c == 'r' { set s = s + "\r"; }
		else if c == 'f' { set s = s + "\f"; }
		else if c == 'x' {
			let hi = self.peek_advance()
			if self.is_eof() { do start.abort("Unterminated string encountered") }
			let lo = self.peek_advance()
			let p = self.pos()
			set s = s + ((tohex(hi, p) * 16) + tohex(lo, p)).to_ascii()
		} else {
			do start.abort("unknown escape character " + inspect_str(c))
		}
	}

	return TokenKind::String { _: s }
}

fn priv Lexer._parse(): TokenKind {
	do self.strip();

	if self.is_eof() {
		return TokenKind::EOF{}
	}

	let c = self.peek()

	if isdigit(c) {
		return self.parse_number()
	}

	if isletter(c) {
		return self.parse_identifier()
	}

	if (c == "'") || (c == '"') {
		return self.parse_string()
	}

	do self.advance()
	if string_contains('-+*/%<>!;,[]{}():.?', c) {
		return TokenKind::Symbol { _: c }
	}

	if string_contains("=!<>", c) {
		if self.peek() == '=' {
			set c = c + '=';
			do self.advance();
		}

		return TokenKind::Symbol { _: c }
	}

	if (c == '&') || (c == '|') {
		if self.peek_advance() != c {
			do self.abort("unknown token start encountered: " + inspect_str(c))
		}

		return TokenKind::Symbol { _: c + c }
	}

	do self.abort("unknown token start encountered: " + inspect_str(c))
}

fn Lexer.next(): Token {
	let pos = self.pos()
	return Token { kind: self._parse(), pos }
}

fn TokenKind.inspect(): str {
	switch self {
		case _: TokenKind::EOF { return "EOF()" }
		case tn: TokenKind::Number { return "Number(" + tn._.to_str() + ")" }
		case ts: TokenKind::String { return "String(" + inspect_str(ts._) + ")" }
		case ti: TokenKind::Identifier { return "Identifier(" + ti._ + ")" }
		case ty: TokenKind::Symbol { return "Symbol(" + ty._ + ")" }
		case { do abort("unknown TokenKind encountered.") }
	}

	unreachable
}
