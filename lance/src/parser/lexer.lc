import "../utils.lch"
import "lexer.lch"

// in the future, we could have it automatically read from `filename`?
fn Lexer_new(stream: str, filename: str): Lexer {
	return Lexer { stream, index: 0, filename, lineno: 1 }
}

fn Lexer.pos(): StreamPos {
	return StreamPos { lineno: self.lineno, filename: self.filename }
}

fn priv Lexer.is_eof(): bool {
	return self.stream.len() <= self.index
}

fn priv Lexer.peek(): str {
	if self.is_eof() {
		return ""
	}

	return self.stream[self.index]
}

fn priv Lexer.advance() {
	do assert(!self.is_eof(), "advanced past EOF")

	if self.peek() == "\n" {
		set self.lineno = self.lineno + 1
	}

	set self.index = self.index + 1
}

fn priv Lexer.peek_advance(): str {
	let s = self.peek()
	do self.advance()
	return s
}

fn priv Lexer.take_while(cond: fn(str): bool): str {
	let s = ""

	while (cond)(self.peek()) && !self.is_eof() {
		set s = s + self.peek()
		do self.advance()
	}

	return s
}

fn priv Lexer.take_if_starts_with(s: str): bool {
	let s_len = s.len()

	if self.stream.len() < (s_len + self.index) {
		return false
	}

	if self.stream.substr(self.index, s_len) == s {
		set self.lineno = self.lineno + s.count_char_occurrences("\n")
		set self.index = self.index + s_len
		return true
	}

	return false
}

fn priv Lexer.abort(m: str): never {
	do self.pos().abort(m)
}

fn priv str.is_space(): bool {
	return " \n\t\r\f".does_contain_char(self)
}

fn priv str.is_digit(): bool {
	return ('0' <= self) && (self <= '9')
}

fn priv str.is_letter(): bool {
	return (('a' <= self) && (self <= 'z')) || (('A' <= self) && (self <= 'Z')) || (self == '_')
}

fn priv str.is_alnum(): bool {
	return self.is_digit() || self.is_letter()
}

fn priv str.is_quote(): bool {
 	return (self == "'") || (self == '"')
}

fn priv str._is_not_eof(): bool {
	return self != "\n"
}

fn priv Lexer.strip_whitespace(): bool {
	return !self.take_while(str.is_space).is_empty()
}

fn priv Lexer.strip_single_line_comment(): bool {
	if !self.take_if_starts_with('//') {
		return false
	}

	do self.take_while(str._is_not_eof)
	return true
}

fn priv Lexer.strip_multiline_comment(): bool {
	if !self.take_if_starts_with('/*') {
		return false
	}

	let start = self.pos()
	let nesting = 1
	while nesting != 0 {
		if self.is_eof() {
			do start.abort("Missing closing `*/`")
		}

		if self.take_if_starts_with('/*') {
			set nesting = nesting + 1
		} else if self.take_if_starts_with('*/') {
			set nesting = nesting - 1
		} else {
			do self.advance()
		}
	}

	return true
}

fn priv Lexer.strip() {
	while self.strip_whitespace()
		|| self.strip_single_line_comment()
		|| self.strip_multiline_comment() 
	{
		// do nothing, as the strips should do it for us
	}
}

fn priv Lexer.parse_number(): TokenKind {
	let n = ""

	loop {
		let c = self.peek()

		if c.is_digit() {
			set n = n + c
		} else if c == '_' {
			// do nothing
		} else if c.is_letter() {
			do self.abort("bad number suffix " + c.inspect())
		} else {
			break
		}

		do self.advance()
	}

	do assert(!n.is_empty(), "parse number parsed nothing")

	return TokenKind::Number { _: n.to_num() }
}

fn priv iskeyword(s: str): bool {
	let kws = [
		"global", "fn", "priv", "struct", "enum", "extern", "externf", "import",
		"if", "else", "while", "loop", "for", "return", "do", "switch", "case", "break",
		"continue", "let", "set", "true", "false", "__llvm__"
	]

	let i = 0
	let len = kws.len()

	while i < len {
		if kws[i] == s {
			return true
		}

		set i = i + 1
	}

	return false
}

fn priv Lexer.parse_identifier(): TokenKind {
	let i = self.take_while(str.is_alnum)
	do assert(i != "", "parsing an identifier returned nothing")

	if iskeyword(i) {
		return TokenKind::Symbol { _: i }
	}

	return TokenKind::Identifier { _: i }
}

fn priv str.to_hex(start: StreamPos): num {
	if self.is_digit() {
		return self.to_num()
	}

	if ('a' <= self) && (self <= 'f') {
		return self.to_ascii() - 97 // 97 is `a` in ascii
	}

	if ('A' <= self) && (self <= 'F') {
		return self.to_ascii() - 64 // 64 is `A` in ascii
	}

	do start.abort("unknown hex character " + self.inspect())
}

fn priv Lexer.parse_string(): TokenKind {
	let start = self.pos()
	let quote = self.peek_advance()
	do assert(quote.is_quote(), "invalid starting char for string " + quote.inspect())

	let s = ""

	loop {
		if self.is_eof() {
			do start.abort("Unterminated string encountered")
		}

		let c = self.peek_advance()
		if c == quote {
			break
		}

		if c != "\\" {
			set s = s + c
			continue
		}

		if self.is_eof() {
			do start.abort("Unterminated string encountered")
		}
		set c = self.peek_advance()

		if quote == "'" {
			if (c == "\\") || (c == "'") {
				set c = "\\" + c
			}

			set s = s + c
			continue
		}

		do assert(quote == '"', "quote is not single or double?")

		if "\"\'\\".does_contain_char(c) { set s = s + c; }
		else if c == 'n' { set s = s + "\n"; }
		else if c == 't' { set s = s + "\t"; }
		else if c == 'r' { set s = s + "\r"; }
		else if c == 'f' { set s = s + "\f"; }
		else if c == 'x' {
			let hi = self.peek_advance()

			if self.is_eof() {
				do start.abort("Unterminated string encountered")
			}

			let lo = self.peek_advance()
			let p = self.pos()
			set s = s + ((hi.to_hex(p) * 16) + lo.to_hex(p)).to_ascii()
		} else {
			do start.abort("unknown escape character " + c.inspect())
		}
	}

	return TokenKind::String { _: s }
}

fn priv Lexer.parse_symbol(): TokenKind {
	let c = self.peek_advance()

	// lone symbols
	if "(){}[];,.?".does_contain_char(c) {
		return TokenKind::Symbol { _: c }
	}

	// symbols that can optionally have an `=` following them.
	if '+-*/%<>=!'.does_contain_char(c) {
		if self.peek() == '=' {
			do self.advance()
			set c = c + '='
		}

		return TokenKind::Symbol { _: c }
	}

	// Symbols that can optionally be repeated
	if '&|:'.does_contain_char(c) {
		if self.peek() == c {
			do self.advance()
			set c = c + c
		}

		return TokenKind::Symbol { _: c }
	}
	
	do self.abort("unknown token start encountered: " + c.inspect())
}

fn priv Lexer._parse(): TokenKind {
	do self.strip();

	if self.is_eof() {
		return TokenKind::EOF{}
	}

	let c = self.peek()

	if c.is_digit() {
		return self.parse_number()
	}

	if c.is_letter() {
		return self.parse_identifier()
	}

	if c.is_quote() {
		return self.parse_string()
	}

	return self.parse_symbol()
}

fn Lexer.next(): Token {
	let pos = self.pos()
	return Token { kind: self._parse(), pos }
}
